{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Stocks Using Machine Learning\n",
    "## Collection\n",
    "<hr>\n",
    "\n",
    "The goal of this notebook is to provide collection methods for attributes that we believe will be important to predicting a stock's price movement. After collection and compiliation into a dataframe, data will be pickled for Cleaning and EDA.\n",
    "\n",
    "### Objectives\n",
    " - Collect Ticker and Date\n",
    " - Collect Open Price\n",
    " - Collect Close Price\n",
    " - Collect Volume\n",
    " - Collect News Sentiment Score\n",
    "    - Full article sentiment more accurate than just headline (perform on full content if possible)\n",
    " - Collect Social Sentiment Score\n",
    " - Collect Related Stock Sentiment Score\n",
    "   - Collect related stock tickers that are found within articles\n",
    "   - Compile into a list based on frequency\n",
    "   - Apply weighted social and news sentiment of these related stock to the primary stock\n",
    "   \n",
    "### Organization of data\n",
    "\n",
    "Data must be organized based on ticker and date. After collection is complete, a label will be applied for the **next day's** closing price to evalute whether the sentiment affects stock price.\n",
    "\n",
    "### Sample Stocks\n",
    "\n",
    "Due to the need to collect articles on both the original ticker, and any ticker collected while reading articles, we will limit collect to various stocks across different industries.\n",
    "\n",
    " - Tech\n",
    "   - UBER\n",
    "   - FB\n",
    "   - ORCL\n",
    "   - PYPL\n",
    "   - CSCO\n",
    "   - MSFT\n",
    " - Finance\n",
    "   - BAC\n",
    "   - WFC\n",
    "   - C\n",
    "   - JPM\n",
    "   - V\n",
    "   - MS\n",
    " - Electronics\n",
    "   - AMD\n",
    "   - AAPL\n",
    "   - MU\n",
    "   - INTC\n",
    "   - NOK\n",
    "   - BA\n",
    " - Health\n",
    "   - PFE\n",
    "   - JNJ\n",
    " - Retail\n",
    "   - COST\n",
    "   - WMT\n",
    "   - HD\n",
    "   - CVS\n",
    "   - BABA\n",
    "   - KR\n",
    " - Energy\n",
    "   - BP\n",
    "   - XOM\n",
    "   - CVX\n",
    " - Transportation\n",
    "   - AAL\n",
    "   - DAL\n",
    "   - LUV\n",
    "   - CSX\n",
    "   - XPO\n",
    "   - UPS\n",
    " - Consumer Items (durables)\n",
    "   - F\n",
    "   - GM\n",
    "   - ATVI\n",
    "   - TSLA\n",
    "   - GT\n",
    "   - EA\n",
    "   - HMC\n",
    " - Consumer Items (non-durables)\n",
    "   - KO\n",
    "   - ABEV\n",
    "   - UAA\n",
    "   - PG\n",
    "   - NKE\n",
    "   - GIS\n",
    " - Communication\n",
    "   - T\n",
    "   - VZ\n",
    "   - TMUS\n",
    " - Services\n",
    "   - AMC\n",
    "   - VIAC\n",
    "   - MGM\n",
    "   - CMCSA\n",
    "   - DIS\n",
    "   - WEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tickers = [\"UBER\",\"FB\",\"ORCL\",\"PYPL\",\"CSCO\",\"MSFT\",\"BAC\",\"WFC\",\\n \"C\",\"JPM\",\"V\",\"MS\",\"AMD\",\"AAPL\",\"MU\",\"INTC\",\"NOK\",\\n \"BA\",\"PFE\",\"JNJ\",\"COST\",\"WMT\",\"HD\",\"CVS\",\"BABA\",\"KR\",\\n \"BP\",\"XOM\",\"CVX\",\"AAL\",\"DAL\",\"LUV\",\"CSX\",\"XPO\",\"UPS\",\\n \"F\",\"GM\",\"ATVI\",\"TSLA\",\"GT\",\"EA\",\"HMC\",\"KO\",\"ABEV\",\\n \"UAA\",\"PG\",\"NKE\",\"GIS\",\"T\",\"VZ\",\"TMUS\",\"AMC\",\"VIAC\",\\n \"MGM\",\"CMCSA\",\"DIS\",\"WEN\"]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our focus will be the last 90 days for each of the following stocks\n",
    "\n",
    "keys = [\"c3s6juiad3ie4i7q63b0\",\"c45oediad3ia3sn569mg\",\n",
    "        \"c45oeliad3ia3sn56a1g\",\"c45of1iad3ia3sn56a7g\",\n",
    "        \"c45ofn2ad3ia3sn56as0\",\"c45oftiad3ia3sn56b10\",\n",
    "        \"c3dhc1iad3icrjj6i7qg\"]\n",
    "\n",
    "#small amt to test prior to full run\n",
    "tickers = [\"UBER\",\"FB\",\"ORCL\",\"PYPL\"]\n",
    "\n",
    "'''tickers = [\"UBER\",\"FB\",\"ORCL\",\"PYPL\",\"CSCO\",\"MSFT\",\"BAC\",\"WFC\",\n",
    " \"C\",\"JPM\",\"V\",\"MS\",\"AMD\",\"AAPL\",\"MU\",\"INTC\",\"NOK\",\n",
    " \"BA\",\"PFE\",\"JNJ\",\"COST\",\"WMT\",\"HD\",\"CVS\",\"BABA\",\"KR\",\n",
    " \"BP\",\"XOM\",\"CVX\",\"AAL\",\"DAL\",\"LUV\",\"CSX\",\"XPO\",\"UPS\",\n",
    " \"F\",\"GM\",\"ATVI\",\"TSLA\",\"GT\",\"EA\",\"HMC\",\"KO\",\"ABEV\",\n",
    " \"UAA\",\"PG\",\"NKE\",\"GIS\",\"T\",\"VZ\",\"TMUS\",\"AMC\",\"VIAC\",\n",
    " \"MGM\",\"CMCSA\",\"DIS\",\"WEN\"]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45oediad3ia3sn569mg\n"
     ]
    }
   ],
   "source": [
    "# Swaps api key to allow more frequent calls\n",
    "\n",
    "FINNHUB_API_KEY = \"c3s6juiad3ie4i7q63b0\"\n",
    "\n",
    "def swap_key(currentKey):\n",
    "    currentKey = keys.index(currentKey) + 1\n",
    "    try:\n",
    "        return keys[currentKey]\n",
    "    except:\n",
    "        #should return zero if idx out of range\n",
    "        return keys[0]\n",
    "\n",
    "# this swaps to the next key\n",
    "# FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time function for date to increment \n",
    "def increment_one_day(str_date):\n",
    "\n",
    "    _date = datetime.strptime(str_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "    _date = _date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return _date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code requires the stanfordCoreNLP to be running as a local server. \n",
    "Download it and run it as a server using the commands below.\n",
    "```\n",
    "cd stanford-corenlp-4.2.2\n",
    "java -mx6g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StanfordCoreNLP Function\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = nlp.annotate(text, properties={\n",
    "                   'annotators': 'sentiment',\n",
    "                   'outputFormat': 'json',\n",
    "                   'timeout': 5000,\n",
    "               })\n",
    "    return np.mean([int(i['sentimentValue']) for i in result['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets news for ticker on a specfic date.\n",
    "def get_news(ticker, date):\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/company-news?symbol={ticker}&from={date}&to={date}&token={FINNHUB_API_KEY}')\n",
    "    \n",
    "    data = r.json()\n",
    "    h = []\n",
    "    for d in data:\n",
    "        d['date'] = datetime.utcfromtimestamp(d['datetime']).strftime('%Y-%m-%d')\n",
    "        h.append([d['id'], d['date'], d['headline'], d['source'], d['summary'],d['url']])\n",
    "\n",
    "    df = pd.DataFrame(h, columns=['id', 'date', 'headline', 'source', 'summary','url'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets_news_sentiment for each ticker. Usually Recent stats (last week or 2 weeks ago stats possibly.)\n",
    "def get_news_sentiment(ticker):\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/news-sentiment?symbol={ticker}&token={FINNHUB_API_KEY}')\n",
    "\n",
    "    data = r.json()\n",
    "    h={}\n",
    "\n",
    "    for d in data:\n",
    "        try:\n",
    "            for i in data[d]:\n",
    "                sd=[]\n",
    "                sd.append(data[d][i])\n",
    "                h[i]=sd\n",
    "\n",
    "        except:\n",
    "            kl=[]\n",
    "            kl.append(data[d])\n",
    "            h[d]=kl\n",
    "\n",
    "    df = pd.DataFrame.from_dict(h)\n",
    "    df.insert(0,'Ticker',ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_social_sent(day,symbol):\n",
    "    day2 = day[:-1] + str(int(day[-1])+1)\n",
    "\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/stock/social-sentiment?symbol={symbol}&token={FINNHUB_API_KEY}&from={day}&to={day2}')\n",
    "    data = r.json()\n",
    "    \n",
    "    scores = []\n",
    "    mentions = []\n",
    "\n",
    "    for i in data['reddit']:\n",
    "        scores.append(i['score'])\n",
    "        mentions.append(i['mention'])\n",
    "    for i in data['twitter']:\n",
    "        scores.append(i['score'])\n",
    "        mentions.append(i['mention'])\n",
    "    \n",
    "    if scores:\n",
    "        products = [a * b for a, b in zip(scores, mentions)]\n",
    "        return sum(products)/sum(mentions),sum(mentions)\n",
    "    else:\n",
    "        return -1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets open and close for \n",
    "def get_open_close(day, symbol):\n",
    "    #TODO: open close and vol collection\n",
    "    start_t = day + \" 00:00:00\"\n",
    "    end_t = day + \" 23:59:59\"\n",
    "    start_t = int(time.mktime(datetime.strptime(start_t, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "    end_t = int(time.mktime(datetime.strptime(end_t, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "\n",
    "    r = requests.get(f'https://finnhub.io/api/v1/stock/candle?symbol={symbol}&resolution=D&from={start_t}&to={end_t}&token={FINNHUB_API_KEY}')\n",
    "    data = r.json()\n",
    "    \n",
    "    try:\n",
    "        return data['o'][0],data['c'][0],data['v'][0]\n",
    "    except:\n",
    "        return -1,-1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationalStock():\n",
    "    #TODO: relational stock collection\n",
    "    #this may need to be its own notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Where Magic Happens. \n",
    "# Where everything comes together.\n",
    "\n",
    "all_news = pd.DataFrame([])\n",
    "\n",
    "for ticker in tickers:\n",
    "    #start date\n",
    "    _date = '2021-03-15'\n",
    "    \n",
    "    #create empty dataframe\n",
    "    df = pd.DataFrame([])\n",
    "    \n",
    "    #stop date\n",
    "    _fdate = '2021-08-03'\n",
    "    \n",
    "    #loop over dates and get news articles and append to dataframe : limit 60 api calls per minute\n",
    "    while _date != _fdate: #datetime.today().strftime('%Y-%m-%d'):\n",
    "        df = df.append(get_news(ticker, _date))\n",
    "        df = df.drop_duplicates()\n",
    "        FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "        time.sleep(0.15)\n",
    "        _date = increment_one_day(_date)\n",
    "    \n",
    "    #There are some repeat headlines on the same day, so getting a daily headline count per article\n",
    "    #Maybe duplicates of the same headline indicates more important news??\n",
    "    duplicate_headlines = df[['date', 'headline', 'id']]\n",
    "    dh = (duplicate_headlines.groupby(['date', 'headline'], as_index=False)\n",
    "          .count()\n",
    "          .rename(columns={'id': 'headline_count'}))\n",
    "      \n",
    "    # Get unique headlines by date\n",
    "    no_dups = df.drop_duplicates(subset=['date', 'headline'])\n",
    "    \n",
    "    #Merge in headline counts\n",
    "    no_dups = no_dups.merge(dh, how='left', on=['date', 'headline'])\n",
    "    \n",
    "    #Insert ticker\n",
    "    no_dups.insert(0, 'ticker', ticker)\n",
    "    \n",
    "    #Append to dataframe that has all tickers\n",
    "    all_news = all_news.append(no_dups)\n",
    "    \n",
    "all_news.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the articles with same date and ticker is merged into a list.\n",
    "all_news_1=pd.DataFrame(all_news.groupby(['ticker','date'])['headline'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gets the score of those list of articles for each ticker for each date\n",
    "finals=[]\n",
    "for i,j in dict(all_news_1).items():\n",
    "    for k in j:\n",
    "        score=[]\n",
    "        for l in k:\n",
    "            try: \n",
    "                score.append(get_sentiment(l))\n",
    "            except:\n",
    "                score.append(-1)\n",
    "        finals.append(round(np.mean(score),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the sentiment score to dataframe column\n",
    "all_news_1['news_sentiment_score']=finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds sources\n",
    "all_news_3=pd.DataFrame(all_news.groupby(['ticker','date'])['source'].apply(list))\n",
    "all_news_1[\"source\"] = all_news_3[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds url\n",
    "all_news_2=pd.DataFrame(all_news.groupby(['ticker','date'])['url'].apply(list))\n",
    "all_news_1[\"url\"] = all_news_2[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies amount of articles\n",
    "a=all_news_1.reset_index()\n",
    "a['amount_of_articles']=a['headline'].apply(lambda x: len(x))\n",
    "\n",
    "a['date'] = a['date'].apply(lambda x: datetime.strftime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# collecting the opens, closes, and vols\n",
    "opens = []\n",
    "closes =  []\n",
    "vols = []\n",
    "for idx,row in a.iterrows():\n",
    "    FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "    time.sleep(0.15)\n",
    "    o,c,v = get_open_close(row['date'], row['ticker'])\n",
    "    opens.append(o)\n",
    "    closes.append(c)\n",
    "    vols.append(v)\n",
    "    \n",
    "b = {'open': opens, 'close': closes, 'volume': vols}\n",
    "b = pd.DataFrame(data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"open\"] = b[\"open\"]\n",
    "a[\"close\"] = b[\"close\"]\n",
    "a[\"volume\"] = b[\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# collecting sentiments\n",
    "sents=[]\n",
    "mentions=[]\n",
    "for idx,row in a.iterrows():\n",
    "    FINNHUB_API_KEY = swap_key(FINNHUB_API_KEY)\n",
    "    time.sleep(0.15)\n",
    "    s,m = get_social_sent(row['date'],row['ticker'])\n",
    "    sents.append(s)\n",
    "    mentions.append(m)\n",
    "    \n",
    "c = {'social_sentiments': sents, 'mentions': mentions}\n",
    "c = pd.DataFrame(data=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "a[\"social_sentiments\"] = c[\"social_sentiments\"]\n",
    "a[\"mentions\"] = c[\"mentions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>news_sentiment_score</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>amount_of_articles</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>social_sentiments</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FB</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>[Onetime Home of Warner Bros.’ Harry Warner As...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[DowJones]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=7dbe5db9757dda...</td>\n",
       "      <td>1</td>\n",
       "      <td>125.340</td>\n",
       "      <td>125.06</td>\n",
       "      <td>19620967</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FB</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>[Rupert Murdoch's News Corp strikes deal as Fa...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[The Guardian, https://nypost.com, https://www...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=61c0d589cb8bf9...</td>\n",
       "      <td>70</td>\n",
       "      <td>269.080</td>\n",
       "      <td>273.75</td>\n",
       "      <td>16856746</td>\n",
       "      <td>0.066288</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>[NetApp reformula a organização de vendas glob...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>[businesswire, benzinga, businesswire, busines...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=6479351ac59fa2...</td>\n",
       "      <td>89</td>\n",
       "      <td>276.085</td>\n",
       "      <td>279.28</td>\n",
       "      <td>22437665</td>\n",
       "      <td>-0.339269</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FB</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>[Facebook Promises More Support For Human Righ...</td>\n",
       "      <td>1.89</td>\n",
       "      <td>[https://www.forbes.com, businesswire, busines...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=ad0559e9f8ae60...</td>\n",
       "      <td>58</td>\n",
       "      <td>275.705</td>\n",
       "      <td>284.01</td>\n",
       "      <td>21315044</td>\n",
       "      <td>-0.589213</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FB</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>[Take A Sneak Peek At The Weirdly-Shaped New P...</td>\n",
       "      <td>1.85</td>\n",
       "      <td>[benzinga, benzinga, benzinga, businesswire, b...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=e851ef47ee28e6...</td>\n",
       "      <td>77</td>\n",
       "      <td>279.870</td>\n",
       "      <td>278.62</td>\n",
       "      <td>18754853</td>\n",
       "      <td>-0.361794</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>UBER</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>[Replay: Joby Aviation Executive Chairman and ...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>[Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Uni...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=62bfd8bf18171d...</td>\n",
       "      <td>30</td>\n",
       "      <td>44.120</td>\n",
       "      <td>44.69</td>\n",
       "      <td>51033697</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>UBER</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>[Uber looks beyond ride-hailing as rebound and...</td>\n",
       "      <td>2.06</td>\n",
       "      <td>[Yahoo, Yahoo, DowJones, CNBC, Yahoo, Yahoo, Y...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=e725733cc1743a...</td>\n",
       "      <td>18</td>\n",
       "      <td>44.380</td>\n",
       "      <td>43.46</td>\n",
       "      <td>22194938</td>\n",
       "      <td>0.195272</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>UBER</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>[Why No One Should Invest in Food Delivery Sto...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[Yahoo, MarketWatch, SeekingAlpha, SeekingAlpha]</td>\n",
       "      <td>[https://finnhub.io/api/news?id=1185c1d8cba9af...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>UBER</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>[Videogames entered the mainstream in the pand...</td>\n",
       "      <td>2.08</td>\n",
       "      <td>[Yahoo, Yahoo, MarketWatch, MarketWatch, Marke...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=90034f7a2d7274...</td>\n",
       "      <td>13</td>\n",
       "      <td>44.100</td>\n",
       "      <td>43.49</td>\n",
       "      <td>26579889</td>\n",
       "      <td>0.148094</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>UBER</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>[Disney, Google and other U.S. companies requi...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>[Yahoo, Yahoo, Yahoo, MarketWatch, Yahoo, Yaho...</td>\n",
       "      <td>[https://finnhub.io/api/news?id=4d0fe9d5700b42...</td>\n",
       "      <td>28</td>\n",
       "      <td>44.100</td>\n",
       "      <td>43.49</td>\n",
       "      <td>26579889</td>\n",
       "      <td>-0.072947</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                           headline  \\\n",
       "0       FB  2016-08-09  [Onetime Home of Warner Bros.’ Harry Warner As...   \n",
       "1       FB  2021-03-15  [Rupert Murdoch's News Corp strikes deal as Fa...   \n",
       "2       FB  2021-03-16  [NetApp reformula a organização de vendas glob...   \n",
       "3       FB  2021-03-17  [Facebook Promises More Support For Human Righ...   \n",
       "4       FB  2021-03-18  [Take A Sneak Peek At The Weirdly-Shaped New P...   \n",
       "..     ...         ...                                                ...   \n",
       "521   UBER  2021-07-29  [Replay: Joby Aviation Executive Chairman and ...   \n",
       "522   UBER  2021-07-30  [Uber looks beyond ride-hailing as rebound and...   \n",
       "523   UBER  2021-07-31  [Why No One Should Invest in Food Delivery Sto...   \n",
       "524   UBER  2021-08-01  [Videogames entered the mainstream in the pand...   \n",
       "525   UBER  2021-08-02  [Disney, Google and other U.S. companies requi...   \n",
       "\n",
       "     news_sentiment_score                                             source  \\\n",
       "0                    3.00                                         [DowJones]   \n",
       "1                    2.00  [The Guardian, https://nypost.com, https://www...   \n",
       "2                    1.91  [businesswire, benzinga, businesswire, busines...   \n",
       "3                    1.89  [https://www.forbes.com, businesswire, busines...   \n",
       "4                    1.85  [benzinga, benzinga, benzinga, businesswire, b...   \n",
       "..                    ...                                                ...   \n",
       "521                  1.90  [Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Yahoo, Uni...   \n",
       "522                  2.06  [Yahoo, Yahoo, DowJones, CNBC, Yahoo, Yahoo, Y...   \n",
       "523                  2.00   [Yahoo, MarketWatch, SeekingAlpha, SeekingAlpha]   \n",
       "524                  2.08  [Yahoo, Yahoo, MarketWatch, MarketWatch, Marke...   \n",
       "525                  1.88  [Yahoo, Yahoo, Yahoo, MarketWatch, Yahoo, Yaho...   \n",
       "\n",
       "                                                   url  amount_of_articles  \\\n",
       "0    [https://finnhub.io/api/news?id=7dbe5db9757dda...                   1   \n",
       "1    [https://finnhub.io/api/news?id=61c0d589cb8bf9...                  70   \n",
       "2    [https://finnhub.io/api/news?id=6479351ac59fa2...                  89   \n",
       "3    [https://finnhub.io/api/news?id=ad0559e9f8ae60...                  58   \n",
       "4    [https://finnhub.io/api/news?id=e851ef47ee28e6...                  77   \n",
       "..                                                 ...                 ...   \n",
       "521  [https://finnhub.io/api/news?id=62bfd8bf18171d...                  30   \n",
       "522  [https://finnhub.io/api/news?id=e725733cc1743a...                  18   \n",
       "523  [https://finnhub.io/api/news?id=1185c1d8cba9af...                   4   \n",
       "524  [https://finnhub.io/api/news?id=90034f7a2d7274...                  13   \n",
       "525  [https://finnhub.io/api/news?id=4d0fe9d5700b42...                  28   \n",
       "\n",
       "        open   close    volume  social_sentiments  mentions  \n",
       "0    125.340  125.06  19620967          -1.000000        -1  \n",
       "1    269.080  273.75  16856746           0.066288        45  \n",
       "2    276.085  279.28  22437665          -0.339269        85  \n",
       "3    275.705  284.01  21315044          -0.589213       135  \n",
       "4    279.870  278.62  18754853          -0.361794       534  \n",
       "..       ...     ...       ...                ...       ...  \n",
       "521   44.120   44.69  51033697          -1.000000        -1  \n",
       "522   44.380   43.46  22194938           0.195272        40  \n",
       "523   -1.000   -1.00        -1          -1.000000        -1  \n",
       "524   44.100   43.49  26579889           0.148094        33  \n",
       "525   44.100   43.49  26579889          -0.072947        39  \n",
       "\n",
       "[526 rows x 12 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the final dataframe\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a HDF5 because it saves and loads fast\n",
    "a.to_hdf('stocks.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use below code to recover dataframe\n",
    "#reread = pd.read_hdf('stocks.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
